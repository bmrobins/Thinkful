{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Import Text Libraries\n",
    "import re\n",
    "import string\n",
    "from wordcloud import STOPWORDS\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "\n",
    "#Import Other Libraries\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Import Classifers Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull digital music review data from Json file\n",
    "file = '/Users/mac/Dropbox/Thinkful_Coursework/Course/Unit_3/Lesson 6/Amazon Reviews/digital_music.json'\n",
    "df = pd.read_json(file, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe\n",
      "---------------------------------------------------------------------------------------------\n",
      "No. of Rows: 64706\n",
      "No. of Columns: 9\n",
      "---------------------------------------------------------------------------------------------\n",
      "Column Data Types\n",
      "---------------------------------------------------------------------------------------------\n",
      "asin              object\n",
      "helpful           object\n",
      "overall            int64\n",
      "reviewText        object\n",
      "reviewTime        object\n",
      "reviewerID        object\n",
      "reviewerName      object\n",
      "summary           object\n",
      "unixReviewTime     int64\n",
      "dtype: object\n",
      "---------------------------------------------------------------------------------------------\n",
      "Missing Data in Dataframe\n",
      "---------------------------------------------------------------------------------------------\n",
      "reviewerName      177\n",
      "unixReviewTime      0\n",
      "summary             0\n",
      "reviewerID          0\n",
      "reviewTime          0\n",
      "reviewText          0\n",
      "overall             0\n",
      "helpful             0\n",
      "asin                0\n",
      "dtype: int64\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Number of rows and columns\n",
    "x = 93\n",
    "print('Shape of dataframe')\n",
    "print('-' *x)\n",
    "print('No. of Rows:', df.shape[0])\n",
    "print('No. of Columns:', df.shape[1])\n",
    "print('-' *x)\n",
    "\n",
    "# Check data types\n",
    "print('Column Data Types')\n",
    "print('-' *x)\n",
    "print(df.dtypes)\n",
    "print('-' *x)\n",
    "\n",
    "# Check for missing data\n",
    "print('Missing Data in Dataframe')\n",
    "print('-' *x)\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print('-' *x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Sentiment Feature to classify review scores\n",
    "df['sentiment'] = np.where(df['overall'] >= 4, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postive reviews represent 81.0 % of the dataset\n",
      "Negative reviews represent 19.0 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "#Check classes for imbalance\n",
    "print('Postive reviews represent', round(df['sentiment'].value_counts()[1]/len(df) * 100), '% of the dataset')\n",
    "print('Negative reviews represent', round(df['sentiment'].value_counts()[0]/len(df) * 100), '% of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean review text\n",
    "cleanup_re = re.compile('[^a-z]+')\n",
    "def cleanup(sentence):\n",
    "    sentence = str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = cleanup_re.sub(' ', sentence).strip()\n",
    "    return sentence\n",
    "\n",
    "#Apply cleanup function\n",
    "df['review_text_clean'] = df['reviewText'].apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test dataframes\n",
    "split_df = df[['review_text_clean' , 'sentiment']]\n",
    "train_df = split_df.sample(frac=0.8,random_state=200)\n",
    "test_df =  split_df.drop(train_df.index)\n",
    "\n",
    "X_train = train_df['review_text_clean']\n",
    "X_test = test_df['review_text_clean']\n",
    "\n",
    "y_train = train_df['sentiment']\n",
    "y_test = test_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert review text to get token count matrix of token\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.remove(\"not\")\n",
    "\n",
    "count_vect = CountVectorizer(min_df=2 ,stop_words=stopwords , ngram_range=(1,2))\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "sm = SMOTE(ratio = 1.0)\n",
    "\n",
    "#Normalize train count matrix to tf-idf representation\n",
    "X_train_counts = count_vect.fit_transform(X_train) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train_counts, y_train)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_res)\n",
    "\n",
    "#Normalize test count matrix to tf-idf representation\n",
    "X_new_counts = count_vect.transform(X_test)\n",
    "X_test_res, y_test_res = sm.fit_sample(X_new_counts, y_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and Run Classifer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define various classifers for voting\n",
    "lr = LogisticRegression(solver='lbfgs' , C=1000)\n",
    "rf = RandomForestClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "gnb = GaussianNB()\n",
    "brb = BernoulliNB()\n",
    "mnb = MultinomialNB()\n",
    "knn = KNeighborsClassifier()\n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Accuracy : 0.7944631680308136\n",
      "[[7566 2819]\n",
      " [1450 8935]]\n",
      "Bernoulli Accuracy : 0.7563793933558016\n",
      "[[7116 3269]\n",
      " [1791 8594]]\n",
      "Logistic Regression Accuracy : 0.7957149735194993\n",
      "[[6639 3746]\n",
      " [ 497 9888]]\n",
      "Gradient Booster Accuracy : 0.7629754453538757\n",
      "[[6621 3764]\n",
      " [1159 9226]]\n"
     ]
    }
   ],
   "source": [
    "#Fit MultinomialNB Classifer\n",
    "mnb.fit(X_train_tfidf , y_train_res)\n",
    "print(\"Multinomial Accuracy : {}\".format(mnb.score(X_test_tfidf , y_test_res)))\n",
    "y_pred_mnb = mnb.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test_res, y_pred_mnb))\n",
    "\n",
    "#Fit BernoulliNB Classifer\n",
    "brb.fit(X_train_tfidf, y_train_res)\n",
    "print(\"Bernoulli Accuracy : {}\".format(brb.score(X_test_tfidf , y_test_res)))\n",
    "y_pred_brb = brb.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test_res, y_pred_brb))\n",
    "\n",
    "#Fit Logistic Regression Classifer\n",
    "lr.fit(X_train_tfidf, y_train_res)\n",
    "print(\"Logistic Regression Accuracy : {}\".format(lr.score(X_test_tfidf , y_test_res)))\n",
    "y_pred_lr = lr.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test_res, y_pred_lr))\n",
    "\n",
    "#Fit Gradient Booster Classifer\n",
    "gb.fit(X_train_tfidf, y_train_res)\n",
    "print(\"Gradient Booster Accuracy : {}\".format(gb.score(X_test_tfidf , y_test_res)))\n",
    "y_pred_gb = gb.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test_res, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy : 0.7100625902744343\n",
      "[[5213 5172]\n",
      " [ 850 9535]]\n"
     ]
    }
   ],
   "source": [
    "#Fit Random Forest Classifer\n",
    "rf.fit(X_train_tfidf, y_train_res)\n",
    "print(\"Random Forest Accuracy : {}\".format(rf.score(X_test_tfidf , y_test_res)))\n",
    "y_pred_rf = rf.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test_res, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Fit Decision Tree Classifer\n",
    "# dtc.fit(X_train_tfidf, y_train_res)\n",
    "# print(\"Decision Tree Accuracy : {}\".format(dtc.score(X_test_tfidf , y_test_res)))\n",
    "# y_pred_dtc = dtc.predict(X_test_tfidf)\n",
    "# print(confusion_matrix(y_test_res, y_pred_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7992296581608088"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Voting Classifer with Hard Voting\n",
    "vc = VotingClassifier(estimators=[('lr', lr), ('rf', rf),('gb',gb) ,('mnb',mnb),('brb', brb)], voting='hard')\n",
    "\n",
    "vc.fit(X_train_tfidf, y_train_res)\n",
    "vc.score(X_test_tfidf, y_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6945 3440]\n",
      " [ 730 9655]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_vc = vc.predict(X_test_tfidf)\n",
    "vc_cm = confusion_matrix(y_test_res, y_pred_vc)\n",
    "print(vc_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.87530091478094\n",
      "92.97063071738084\n"
     ]
    }
   ],
   "source": [
    "neg_accuracy = (vc_cm[0][0]/(vc_cm[0][0] + vc_cm[0][1])) * 100\n",
    "print(neg_accuracy)\n",
    "\n",
    "pos_accuracy = (vc_cm[1][1]/(vc_cm[1][0] + vc_cm[1][1])) * 100\n",
    "print(pos_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial data set was highly unbalanced towards positive reviews, as 81% of reviews were positive and only 19% were negative.  Running classifers on the unbalanced dataset, produced an mean accuracy score of 80% with Logistic Regression performing the best at 88%.  However, these models were extremely poor at correctly classifying negative reviews at 17% for the Bernoulli model.  After using the smote oversampling method, the overall accuracy was reduced to 80%; however, the model accuracy for negative reviews increased to 68%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
